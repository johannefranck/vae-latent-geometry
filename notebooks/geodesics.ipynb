{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e73aed6",
   "metadata": {},
   "source": [
    "## Explainer notebook\n",
    "\n",
    "Wall through of the computations, algorithms and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41916fb",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "The Tasic et al. (Nature 2018) single-cell RNA-seq dataset is used, containing gene expression profiles from 23,822 cells isolated from the adult mouse visual cortex Kobak and Berens (2019). The dataset is used in preprocessed form; PCA reduced dimensionality of 50 components. The PCA-reduced data is available via the accompanying GitHub repository Berens and Kobak (2019). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a9252",
   "metadata": {},
   "source": [
    "#### Motivation\n",
    "\n",
    "Deep latent variable models (DLVMs) are powerful tools for uncovering low-dimensional structure in high-dimensional data. The goal is not merely to compress data, but to learn representations that reflect the underlying mechanisms of the observed phenomena.\n",
    "\n",
    "However, in VAEs and similar deep generative models, the latent variables themselves are not identifiable. Multiple different latent representations can yield the same observed data distribution. As a result, the learned latent variables are not unique and can vary significantly across training runs, making interpretation difficult Hauberg (2025).\n",
    "\n",
    "Recent work has shown that while the latent variables themselves are not identifiable, certain geometric relationships between them — such as distances, angles, and volumes, when defined using the pullback metric via the decoder — can be statistically identifiable under mild assumptions Syrota et al. (2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846941b4",
   "metadata": {},
   "source": [
    "#### Objective and Aim\n",
    "\n",
    "Under the manifold hypothesis, it is assumed that the data lie near a lower-dimensional manifold embedded in a highdimensional space. A variational autoencoder (VAE) or an ensemble VAE is used to learn this manifold.\n",
    "\n",
    "The objective is to compare distance matrices and evaluate whether geodesic distances better preserve structure than Euclidean distances in the latent space.\n",
    "\n",
    "* The first experiment is set up with a single VAE. One encoder, one decoder.\n",
    "* The second experiment is set up with an EVAE. Where the encoder is shared across decoders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e870e",
   "metadata": {},
   "source": [
    "#### Single VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c5413",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
